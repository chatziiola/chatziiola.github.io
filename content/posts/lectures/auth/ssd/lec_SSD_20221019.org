#+TITLE: Διάλεξη 5: Γνωστές Κατανομές
#+FILETAGS: lecture
#+DATE: <2022-10-19>
#+FILETAGS: lecture
#+COURSE: SSD
#+INSTITUTION: A.U.Th

#+begin_comment
Ουσιαστικά αυτά είναι χωρίς την αρχή της διάλεξης
- Συμπλήρωσα την διάλεξη βάζοντας από βιβλίο και πανά έξτρα κατανομές.
#+end_comment

#+begin_note
Από βιβλίο Καραγιαννίδη και Χατζηδιαμαντή: *σελίδες 255,271*
#+end_note

* Σύνοψη
Αρχικά είναι σημαντικό κανείς να διακρίνει τις κατανομές βάση της φύσεως των
τυχαίων μεταβλητών τους. Να τις χωρίσει, δηλαδή, σε διακριτές και συνεχείς
κατανομές.

** Διακριτές

#+CAPTION: Μια γενική εικόνα των διακριτών κατανομών
| Κατανομή        | Περιγραφή                                               | ΣΜΠ                                                                                    |
|------------------+----------------------------------------------------------+----------------------------------------------------------------------------------------|
| Bernoulli        | Πείραμα με 2 αποτελέσματα: 0,1                        | $f_x(x) = \begin{cases} p &x=1\\ q=1-p &x=0 \end{cases}$                               |
| Διωνυμική       | Επιτυχίες σε n Bernoulli                                | $f_x(x) = \binom{n}{x}p^x(1-p)^{n-x}$                                                  |
| Πολυωνυμική     | Πείραμα με k αποτελέσματα (Γενίκευση πολυωνυμικής) | $f(x_1,x_2,\cdots) = \binom{n}{x_1,x_2,\cdots}p_1^{x_1},p_2^{x_2},\cdots$              |
| Γεωμετρική      | Πλήθος δοκιμών πριν την _πρώτη_ επιτυχία               | $f_{X}(x) = p(1-p)^{x-1}$                                                              |
| Πασκάλ           | Πλήθος δοκιμών πριν την _κοστή_ επιτυχία[fn:1]         | $f_{X_k}(x) = \binom{x-1}{k-1}p^k(1-p)^{x-k}$                                          |
| Υπεργεωμετρική | Πλήθος επιτυχιών σε τυχαία δειγματοληψία            | $f_{X_K}(x) = \frac{\binom{N-k}{n-x} \binom{k}{x}}{\binom{N}{n}$                       |
| Poisson          | Πλήθος αποτελεσμάτων εντός δεδομένου χρόνου         | $f_{X}(x) = \frac{\lambda^x}{x!}e^{-\lambda}$                                          |
| Ομοιόμορφη      | (-_-)                                                    | $f_X(x) = \begin{cases} \frac{1}{b-a}, &x\in [a,b]\\ 0 &\text{elsewhere} \end{cases}$ |


#+CAPTION: Πίνακας αναφοράς για ΔΚ
| Κατανομή        | $\mu$         | $\sigma^2$                |
|------------------+---------------+---------------------------|
| Bernoulli        | $p$           | $p(1-p)$                  |
| Διωνυμική       | $np$          | $np(1-p)$                 |
| Γεωμετρική      | $\frac{1}{p}$ | $\frac{q}{p^2}$           |
| Πασκάλ           | $\frac{k}{p}$ | $k*\frac{q}{p^2}$         |
| Υπεργεωμετρική | $np$          | $np(1-p) \frac{N-n}{N-1}$ |
| Poisson          | $\lambda$     | $\lambda$                 |

** Συνεχείς
Εφεξής ΣΚ.


#+CAPTION: Συνοπτικός πίνακας για τις ΣΚ.
| Κατανομή           | Περιγραφή                                                                       | ΣΜΠ                                                                            |
|---------------------+----------------------------------------------------------------------------------+--------------------------------------------------------------------------------|
| Gaussian            | Γιατί γίνεται να υπάρξει μάθημα μηχανικού χωρίς Gauss?                      | $f_X(x) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{- \frac{(x-\mu)^2}{2\sigma^2}}$      |
| Λογαριθμοκανονική | /Αντίγραψε την μα άλλαξε την να μην μας καταλάβουνε/                         | $f_X(x) = \frac{1}{\sqrt{2\pi\sigma^2}x}e^{- \frac{(\ln{x}-\mu)^2}{2\sigma^2}$ |
| Εκθετική           | Όπου λογάριθμος και εκθετική. Ενδεικτική του χρόνου μεταξύ δύο γεγονότων | $f_X(x) = \lambda e^{-\lambda x}$                                              |
| Erlang              | Εκθετική μα για τον χρόνο μεταξύ κ γεγονότων                                   |$f_X(x) = \frac{\lambda^{k-1}x^{k-1}}{(k-1)!}\lambda e^{-\lambda x}$                                                                                |
| Laplace             | /Αντίγραψε την μα άλλαξε την να μην μας καταλάβουνε/                         | $f_X(x) = \frac{1}{2}\lambda e^{-\lambda\abs{x}}$                              |




| Κατανομή           | $\mu$                         | $\sigma^2$                           |
|---------------------+-------------------------------+--------------------------------------|
| Gaussian            | $\mu$                         | $\sigma^2$                           |
| Λογαριθμοκανονική | $e^{\mu+ \frac{\sigma^2}{2}}$ | $e^{2\mu+ \sigma^2}(e^{\sigma^2}-1)$ |
| Εκθετική           | $ \frac{1}{\lambda}$          | $ \frac{1}{\lambda^2}$               |
| Erlang              | $ \frac{k}{\lambda}$          | $ \frac{k}{\lambda^2}$               |

* Διακριτές Κατανομές
** Bernoulli
Η κατανομή Bernoulli είναι πολύ απλή στην κατανόηση: έστω ότι έχουμε ένα πείραμα
με μόνο δύο πιθανά αποτελέσματα (επιτυχία ή αποτυχία), με το αποτέλεσμα του να
δίνεται από την τιμή της τμ $X$, 1 ή 0 αντίστοιχα. Αυτού του είδους τα πειράματα
λέγονται *πειράματα Bernoulli*, και η $X$ λέμε πως ακολουθεί κατανομή Bernoulli:

Έχει ΣΜΠ:
\begin{equation}
\label{eq:13}
f_X(x)=
\begin{cases}
p & \text{success}\\
1-p &\text{failure}
\end{cases} 
\end{equation}

Το οποίο σε μορφή συναρτήσεων συνεχούς χρόνου μπορεί να γραφτεί ως εξής:
\begin{equation*}
f_X(x)= p\delta(x-1) + (1-p)\delta(x) 
\end{equation*}

** Binomial
/Χτίζοντας επί της [[*Bernoulli][Bernoulli]]:/ Έστω ότι επαναλαμβάνουμε το πείραμα Bernoulli $n$
φορές. Η τυχαία μεταβλητή που *μετρά το πλήθος των επιτυχιών σε $n$ ανεξάρτητες
δοκιμές Bernoulli* ακολουθεί διωνυμική κατανομή και η ΣΜΠ της δίνεται από την:

\begin{equation}
\label{eq:14}
f_x(x) = p_x(x) = \binom{n}{x} p^x(1-p)^{n-x}
\end{equation}

Η διωνυμική κατανομή μπορεί να χρησιμοποιηθεί _όταν η σειρά με την οποία ήρθαν
τα αποτελέσματα έχει σημασία_.

Μπορεί να γραφεί ως pdf με την χρήση $\delta$ functions, όπως είδαμε και στην Bernoulli.

\begin{equation}
\label{eq:15}
F_y(y)=\sum_{k=0}^y \binom{n}{k}p^k(1-p)^{n-k}
\end{equation}

** Γεωμετρική κατανομή
Έστω και πάλι πως επαναλαμβάνουμε ένα πείραμα Bernoulli $X$ φορές: τόσες όσες
χρειάζεται για να έχουμε την πρώτη επιτυχία. Η τυχαία μεταβλητή $X$, που
*περιγράφει τον αριθμό των δοκιμών μέχρι την πρώτη επιτυχία* ακολουθεί γεωμετρική
κατανομή με:
\begin{equation}
\label{eq:2}
f_X(x) = p(1-p)^{x-1}
\end{equation}

/Προκύπτει πολύ εύκολα, όπως και οι περισσότερες διακριτές κατανομές με την λογική/
** Pascal 
Όταν μία τμ $X$ λέμε πως ακολουθεί κατανομή Pascal, ή αλλιώς *αρνητική διωνυμική*,
τότε η τιμή της είναι ενδεικτική του πλήθους των δοκιμών που χρειάστηκαν μέχρι
την $k$-οστή επιτυχία ( ή του πλήθους των αποτυχιών που χρειάστηκαν, με μία
μικρή μεταβολή στους τύπους )

Αν και το όνομα είναι αρκετά παραπλανητικό, έχει άμεση σχέση με την γεωμετρική
κατανομή. Ακόμα ο όρος $\binom{k-1}{x-1}$ έχει αυτή την μορφή καθώς ξέρουμε ήδη
πως το τελευταίο στοιχείο θα είναι (η $k$οστή) επιτυχία.

** Υπεργεωμετρική
Μια πολύ ενδιαφέρουσα κατανομή γιατί αν και συναντάει ευρεία εφαρμογή σε
πειράματα Bernoulli μπορεί να επεκταθεί και σε συνθετότερα πειράματα (με
περισσότερα αποτελέσματα).

**** Το γενικό concept (εξήγηση για πειράματα Bernoulli)
Έστω οτι έχουμε πραγματοποιήσει $N$ επαναλήψεις ενός πειράματος Bernoulli, στις
οποίες οι $k$ ήταν επιτυχίες. /Αυτό προφανώς σημαίνει πως οι $(N-k)$ ήταν
αποτυχίες/. Αν ορίσουμε τμ Χ τέτοια ώστε να περιγράφει το πλήθος επιτυχιών σε μία
τυχαία δειγματοληψία (επιλογή $n$ *τυχαίων* στοιχείων εκ των $Ν$ ), τότε εκείνη
λέμε οτι ακολουθεί _υπεργεωμετρική_ κατανομή, και η ΣΜΠ της δίνεται από την:
\begin{equation}
\label{eq:3}
f_X(x) = \frac{\binom{N-k}{n-x} \binom{k}{x}}{\binom{N}{n}}
\end{equation}

**** Επέκταση για $z$ διαφορετικά αποτελέσματα
Τώρα αν το πείραμα μας δεν έχει μόνο 2 αλλά $z$ διαφορετικά αποτελέσματα και
$N_i\forall i<z$ ο αριθμός των πειραμάτων που /έφεραν/ το $i$οστό αποτέλεσμα
έχουμε[fn:2]:
\begin{equation}
\label{eq:4}
f(x_1,x_2,x_3,x_4,\cdots) = \frac{\binom{N_1}{x_1} \binom{N_2}{x_2} \binom{N_3}{x_3} \binom{N_4}{x_4} \cdots}{\binom{N}{n}}
\end{equation}

#+begin_comment
 # * Poisson
 # Για την κατανόηση της κατανομής Poisson, είναι απαραίτητη η διευκρίνηση των
/ # πειραμάτων/ Poisson.
 # 
 # *** Πείραμα Poisson
 # Ως πείραμα Poisson ορίζουμε εκείνο του 
 # 
 # *** Επεξήγηση της κατανομής
#+end_comment

* Συνεχείς
** Gaussian Κανονική
- *Η μόνη της οποίας το πλήρες μοντέλο προσδιορίζεται από μόνο δύο ροπές.* Αν
  ξέρεις μέση τιμή και διασπορά ξέρεις τα πάντα.
- Η γραφική της παράσταση είναι πολύ εύκολη στην αναγνώριση: /καμπάνα/
- Συχνά, μία μεταβλητή ακολουθεί κανονική κατανομή την συμβολίζουμε ως: $X\simN(\mu,\sigma^{2})$
- *Εξαιρετικά κρίσιμη* όπως θα φανεί σε επόμενη διάλεξη γιατί προσεγγίζει /όλες/ τις
  κατανομές.
  - Με αυτόν τον τρόπο, για παράδειγμα, σχετίζεται με τον θόρυβο στις τηλεπικοινωνίες.

*** Μετασχηματισμός μεταβλητής με κανονική κατανομή
Έστω ότι έχουμε τμ $X$ που ακολουθεί κανονική κατανομή:
\begin{equation}
\label{eq:5}
X\sim N(\mu,\sigma^2)\\
\end{equation}

τότε:
\begin{equation}
\label{eq:16}
Y = aX +b \Rightarrow Y \sim N(\alpha\mu +b, \alpha\sigma)
\end{equation}

*** Κανονικοποίηση
- Αν δεν έχεις διαβάσει προηγουμένως μια μαθηματική ανάλυση (έστω την επόμενη
  παράγραφο) ίσως το αντικείμενο αυτής δεν είναι τόσο ξεκάθαρο.
- Η ΑΣΚ της κανονικής κατανομής έχει την μορφή:
  
\begin{equation}
\label{eq:6}
F_X(x) = \int_{-\infty}^xf_x(r)dr = \cdots =
\frac{1}{\sqrt{2\pi}}\int_{-\infty}^{\frac{x-\mu}{\sigma}}e^{- \frac{u^2}{2}}du = \Phi(\frac{x-\mu}{\sigma})
\end{equation}

- Το ολοκλήρωμα είναι μόνο αριθμητικά υπολογίσιμο, αναγκάζοντας μας να στραφούμε
  σε πίνακες για τον υπολογισμό του.
- Την ίδια στιγμή, παρατηρώντας την παραπάνω σχέση προκύπτει πως η ΑΣΚ μιας
  οποιασδήποτε τμ $X\sim N(\mu,\sigma^2)$ ανάγεται στην ΑΣΚ της $N(0,1)$
- Οπότε μπορούμε να πούμε ότι /κανονικοποιούμε/ την κανονική  κατανομή υιοθετώντας
  την σχέση $z = \frac{x-\mu}{\sigma}$

*** Σχέση με $\Phi$
#+begin_comment
Αυτό το κομμάτι θα μπορούσε να ξαναγραφεί ώστε να συνδεθούν αυτές οι δύο παράγραφοι.
#+end_comment
Ορίζουμε συνάρτηση
\begin{equation}
\label{eq:7}
\Phi(x) =\frac{1}{\sqrt{2\pi}} \int_{-\infty}^x e^{- \frac{u^2}{2}}du 
\end{equation}
όπως άλλωστε είδαμε και στην προηγούμενη παράγραφο. Έχουμε έτσι:
\begin{equation}
\label{eq:8}
F_X(x) = \Phi(
\frac{x-\mu}{\sigma^{2}})
\end{equation}

Ισχύει η ιδιότητα:
\begin{equation}
\label{eq:9}
\Phi(-x) = 1 - \Phi(x)
\end{equation}


- [ ] Προς ανάπτυξη: Ροπογεννήτρια συνάρτηση και $\Phi$ όπως την είδαμε εδώ.

*** Σχέση με Gaussian $Q$
Ορίζουμε συνάρτηση:
\begin{equation}
\label{eq:10}
Q(x) = 1 - \Phi(x)
\end{equation}

της οποίας η εφαρμογή στα τηλεπικοινωνιακά συστήματα υπογραμμίζεται στο βιβλίο
των Καραγιαννίδη, Χατζηδιαμαντή. Δεν αναλύθηκε ιδιαίτερα στην διάλεξη, πέραν από
την σύνδεσή της με την συνάρτηση λάθους

\begin{equation}
\label{eq:11}
erfc = \text{complimentary }erf(x) = 1 - erf(x) = 2Q(\sqrt{2}x)
\end{equation}

Ακόμα, μέσω αυτής ορίζονται ουσιαστικά τα [[file:lec_SSD_20221017.org::*Όρια Chernoff][Όρια Chernoff - Rubin]]

** Rayleigh                                                        :noexport:
- [ ] το έχασα λίγο
- [ ] Δεν την γράφει κάν το βιβλίο


** Log-Normal                                                      :noexport:
Έστω οτι η Y ακολουθεί κανονική κατανομή η $X=e^Y$ ακολουθεί Log-Normal:
- [ ] CDF
- [ ] PDF
- [ ] Να αποδειχθεί με το θεώρημα μετασχηματισμού

** Εκθετική κατανομή
- Πολύ σημαντικές ιδιότητες:
  
\begin{align}
\label{eq:1}
Pr\{X>a+b\} &= Pr\{X>a\}Pr\{X>b\}\\
Pr\{X>a+b|X>a\} &= Pr\{X>b\}
\end{align}
- η δεύτερη ιδιότητα λέγεται memoryless property

** Erlang
- Όπως γράφει και παραπάνω, χρήσιμη όταν μας ενδιαφέρει ο χρόνος μεταξύ $k$
  διαδοχικών γεγονότων και όχι μόνο δύο, στην οποία περίπτωση και χρησιμοποιούμε
  την εκθετική κατανομή.
- Αναφέρθηκε το παράδειγμα της ουράς σουπερμαρκετ, αυξανόμενου αριθμού πελατών.

** Ακόμα
Αναφερθήκαμε συνοπτικά σε
- Rayleigh
- Weibull


* Footnotes
[fn:2] Ακόμα, εξ' ορισμού ισχύει: $\sum_{i=1}^z N_i = N$

[fn:1] Τώρα να ρωτήσει κανείς *γιατί δεν λέγεται η Πασκάλ υπεργεωμετρική και
λέγεται αρνητική διωνυμική?*
